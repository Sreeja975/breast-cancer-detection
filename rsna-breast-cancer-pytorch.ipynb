{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":5660507,"sourceType":"datasetVersion","datasetId":3251719}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# RSNA Breast Cancer Detection - Auto Threshold Version\n\n# =========================================================\n# 1ï¸âƒ£ Imports\n# =========================================================\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, models, transforms\nfrom sklearn.metrics import roc_curve, precision_score, recall_score\n\n# =========================================================\n# 2ï¸âƒ£ Device\n# =========================================================\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n# =========================================================\n# 3ï¸âƒ£ Dataset Paths\n# =========================================================\nDATA_PATH = \"/kaggle/input/rsna-breast-cancer-detection\"\nTRAIN_DIR = os.path.join(DATA_PATH, \"train\")\nVAL_DIR   = os.path.join(DATA_PATH, \"val\")\n\n# =========================================================\n# 4ï¸âƒ£ Transforms (Improved)\n# =========================================================\ntransform = transforms.Compose([\n    transforms.Resize((224,224)),\n    transforms.ToTensor(),\n    transforms.Normalize(\n        mean=[0.485, 0.456, 0.406],\n        std=[0.229, 0.224, 0.225]\n    )\n])\n\ntrain_dataset = datasets.ImageFolder(TRAIN_DIR, transform=transform)\nval_dataset   = datasets.ImageFolder(VAL_DIR, transform=transform)\n\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\nval_loader   = DataLoader(val_dataset, batch_size=16)\n\nprint(\"Classes:\", train_dataset.classes)\n\n# =========================================================\n# 5ï¸âƒ£ Model Definition\n# =========================================================\nfrom torchvision.models import resnet18, ResNet18_Weights\n\nclass BreastCancerCNN(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.model = resnet18(weights=ResNet18_Weights.DEFAULT)\n        self.model.fc = nn.Linear(self.model.fc.in_features, 1)\n\n    def forward(self, x):\n        return self.model(x)\n\nmodel = BreastCancerCNN().to(device)\n\n# =========================================================\n# 6ï¸âƒ£ Loss & Optimizer (FP-aware)\n# =========================================================\npos_weight = torch.tensor([2.0]).to(device)\ncriterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n\n# =========================================================\n# 7ï¸âƒ£ Training Loop\n# =========================================================\nepochs = 15\n\nfor epoch in range(epochs):\n    model.train()\n    running_loss = 0\n\n    for images, labels in train_loader:\n        images = images.to(device)\n        labels = labels.to(device).unsqueeze(1).float()\n\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n\n    print(f\"Epoch [{epoch+1}/{epochs}] Loss: {running_loss/len(train_loader):.4f}\")\n\n# =========================================================\n# 8ï¸âƒ£ Automatic Threshold Selection (ROC)\n# =========================================================\nmodel.eval()\ny_true = []\ny_scores = []\n\nwith torch.no_grad():\n    for images, labels in val_loader:\n        images = images.to(device)\n        outputs = model(images)\n        probs = torch.sigmoid(outputs).cpu().numpy()\n\n        y_scores.extend(probs.flatten())\n        y_true.extend(labels.numpy())\n\ny_true = np.array(y_true)\ny_scores = np.array(y_scores)\n\n# ROC Curve\nfpr, tpr, thresholds = roc_curve(y_true, y_scores)\n\n# Choose threshold minimizing false positives\noptimal_idx = np.argmin(fpr + (1 - tpr))\noptimal_threshold = thresholds[optimal_idx]\n\nprint(f\"\\nâœ… Automatically selected threshold: {optimal_threshold:.3f}\")\n\n# =========================================================\n# 9ï¸âƒ£ Final Validation Metrics\n# =========================================================\ny_pred = (y_scores >= optimal_threshold).astype(int)\n\nprecision = precision_score(y_true, y_pred)\nrecall    = recall_score(y_true, y_pred)\n\nprint(f\"Precision (â†“ FP): {precision:.4f}\")\nprint(f\"Recall (â†“ FN):    {recall:.4f}\")\n\n# =========================================================\n# ðŸ”Ÿ Save Model & Threshold\n# =========================================================\ntorch.save({\n    \"model_state\": model.state_dict(),\n    \"threshold\": optimal_threshold\n}, \"/kaggle/working/breast_cancer_model_with_threshold.pth\")\n\nprint(\"Model + threshold saved!\")","metadata":{"_uuid":"9c413175-4a2e-41b6-9de9-1e51a9c20223","_cell_guid":"046ab78a-2e4c-4a5c-bd11-e453c6020961","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2026-01-03T14:07:09.192209Z","iopub.execute_input":"2026-01-03T14:07:09.193015Z","iopub.status.idle":"2026-01-03T15:55:57.780253Z","shell.execute_reply.started":"2026-01-03T14:07:09.192984Z","shell.execute_reply":"2026-01-03T15:55:57.779432Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nClasses: ['cancer', 'normal']\nEpoch [1/15] Loss: 0.2039\nEpoch [2/15] Loss: 0.1914\nEpoch [3/15] Loss: 0.1895\nEpoch [4/15] Loss: 0.1869\nEpoch [5/15] Loss: 0.1836\nEpoch [6/15] Loss: 0.1773\nEpoch [7/15] Loss: 0.1679\nEpoch [8/15] Loss: 0.1549\nEpoch [9/15] Loss: 0.1384\nEpoch [10/15] Loss: 0.1219\nEpoch [11/15] Loss: 0.1085\nEpoch [12/15] Loss: 0.0996\nEpoch [13/15] Loss: 0.0923\nEpoch [14/15] Loss: 0.0899\nEpoch [15/15] Loss: 0.0873\n\nâœ… Automatically selected threshold: 1.000\nPrecision (â†“ FP): 0.9750\nRecall (â†“ FN):    0.2391\nModel + threshold saved!\n","output_type":"stream"}],"execution_count":2}]}