{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":5660507,"sourceType":"datasetVersion","datasetId":3251719}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# RSNA Breast Cancer Detection - Kaggle Ready Notebook (ImageFolder Version)\n\n# =========================================================\n# 1️⃣ Imports\n# =========================================================\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, models, transforms\n\n# Set device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n# =========================================================\n# 2️⃣ Dataset Paths\n# =========================================================\nDATA_PATH = \"/kaggle/input/rsna-breast-cancer-detection\"\nTRAIN_DIR = os.path.join(DATA_PATH, \"train\")\nVAL_DIR   = os.path.join(DATA_PATH, \"val\")  # optional\nTEST_DIR  = os.path.join(DATA_PATH, \"test\") # optional\n\nprint(\"Train exists:\", os.path.exists(TRAIN_DIR))\nprint(\"Val exists:\", os.path.exists(VAL_DIR))\nprint(\"Test exists:\", os.path.exists(TEST_DIR))\n\n# =========================================================\n# 3️⃣ Transforms & Datasets\n# =========================================================\ntransform = transforms.Compose([\n    transforms.Resize((224,224)),\n    transforms.ToTensor(),\n])\n\ntrain_dataset = datasets.ImageFolder(TRAIN_DIR, transform=transform)\nval_dataset   = datasets.ImageFolder(VAL_DIR, transform=transform) if os.path.exists(VAL_DIR) else None\ntest_dataset  = datasets.ImageFolder(TEST_DIR, transform=transform) if os.path.exists(TEST_DIR) else None\n\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\nval_loader   = DataLoader(val_dataset, batch_size=16) if val_dataset else None\ntest_loader  = DataLoader(test_dataset, batch_size=16) if test_dataset else None\n\nprint(\"Classes:\", train_dataset.classes)\nprint(\"Number of training samples:\", len(train_dataset))\n\n# =========================================================\n# 4️⃣ Model Definition (ResNet18)\n# =========================================================\nclass BreastCancerCNN(nn.Module):\n    def __init__(self):\n        super(BreastCancerCNN, self).__init__()\n        self.model = models.resnet18(pretrained=True)\n        self.model.fc = nn.Linear(self.model.fc.in_features, 1)  # binary output\n\n    def forward(self, x):\n        return self.model(x)\n\nmodel = BreastCancerCNN().to(device)\n\n# =========================================================\n# 5️⃣ Loss & Optimizer\n# =========================================================\ncriterion = nn.BCEWithLogitsLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n\n# =========================================================\n# 6️⃣ Training Loop\n# =========================================================\nepochs = 15  # Increase as needed\n\nfor epoch in range(epochs):\n    model.train()\n    running_loss = 0\n    correct = 0\n    total = 0\n\n    for images, labels in train_loader:\n        images, labels = images.to(device), labels.to(device).unsqueeze(1).float()\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n        preds = torch.sigmoid(outputs) > 0.5\n        correct += (preds == labels).sum().item()\n        total += labels.size(0)\n\n    train_acc = correct / total\n    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader):.4f}, Train Acc: {train_acc:.4f}\")\n\n# =========================================================\n# 7️⃣ Validation Accuracy\n# =========================================================\nif val_loader:\n    model.eval()\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for images, labels in val_loader:\n            images, labels = images.to(device), labels.to(device).unsqueeze(1).float()\n            outputs = model(images)\n            preds = torch.sigmoid(outputs) > 0.5\n            correct += (preds == labels).sum().item()\n            total += labels.size(0)\n    val_acc = correct / total\n    print(f\"Validation Accuracy: {val_acc:.4f}\")\n\n# =========================================================\n# 8️⃣ Save Model\n# =========================================================\ntorch.save(model.state_dict(), \"/kaggle/working/breast_cancer_cnn.pth\")\nprint(\"Model saved successfully!\")\n\n# =========================================================\n# 9️⃣ Grad-CAM Helper\n# =========================================================\ndef generate_gradcam(model, image, target_layer):\n    model.eval()\n    image = image.to(device)\n\n    gradients = []\n    activations = []\n\n    def backward_hook(module, grad_input, grad_output):\n        gradients.append(grad_output[0])\n\n    def forward_hook(module, input, output):\n        activations.append(output)\n\n    handle_fw = target_layer.register_forward_hook(forward_hook)\n    handle_bw = target_layer.register_backward_hook(backward_hook)\n\n    output = model(image)\n    pred_class = torch.sigmoid(output)\n    model.zero_grad()\n    output.backward()\n\n    grad = gradients[0].cpu().data.numpy()[0]\n    act = activations[0].cpu().data.numpy()[0]\n\n    weights = np.mean(grad, axis=(1,2))\n    cam = np.zeros(act.shape[1:], dtype=np.float32)\n\n    for i, w in enumerate(weights):\n        cam += w * act[i]\n\n    cam = np.maximum(cam, 0)\n    cam = cv2.resize(cam, (224,224))\n    cam = cam - np.min(cam)\n    cam = cam / np.max(cam)\n\n    handle_fw.remove()\n    handle_bw.remove()\n\n    return cam\n\n# =========================================================\n# 10️⃣ Test Grad-CAM\n# =========================================================\nsample_image, label = train_dataset[0]  # Pick first sample\nsample_image_input = sample_image.unsqueeze(0)  # add batch dimension\n\ntarget_layer = model.model.layer4[1].conv2\nheatmap = generate_gradcam(model, sample_image_input, target_layer)\n\nplt.imshow(sample_image.permute(1,2,0))\nplt.imshow(heatmap, cmap='jet', alpha=0.5)\nplt.title(f\"True label: {label}\")\nplt.axis('off')\nplt.show()","metadata":{"_uuid":"9c413175-4a2e-41b6-9de9-1e51a9c20223","_cell_guid":"046ab78a-2e4c-4a5c-bd11-e453c6020961","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}